{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cfadd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing, load_iris\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4045f27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.51524691, 0.21972822, 0.24003557, 0.17667498, 0.20696572,\n",
       "        0.17638631, 0.22801418, 0.19245823]),\n",
       " 0.004450316454950786,\n",
       " 0.9957240028129284)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n=200\n",
    "X=np.random.rand(n,7)\n",
    "\n",
    "for i in range(1,7):\n",
    "    X[:,i]=X[:,0]+np.random.normal(0,0.01,n)\n",
    "y=3*X[:,0]+2*X[:,1]+np.random.normal(0,0.1,n)\n",
    "\n",
    "sc=StandardScaler()\n",
    "\n",
    "X=sc.fit_transform(X)\n",
    "X=np.c_[np.ones(n),X]\n",
    "\n",
    "def ridge_gd(X,y,lr,lmbd,iters):\n",
    "    m,n=X.shape\n",
    "    theta=np.zeros(n)\n",
    "\n",
    "    for _ in range(iters):\n",
    "        y_pred=X.dot(theta)\n",
    "        if np.any(np.isnan(y_pred)) or np.any(np.isinf(y_pred)):\n",
    "            return theta,np.inf,-np.inf\n",
    "        grad=(1/m)*X.T.dot(y_pred-y)+2*lmbd*theta\n",
    "        theta-=lr*grad\n",
    "\n",
    "    y_pred=X.dot(theta)\n",
    "    cost=(1/(2*m))*np.sum((y_pred-y)**2)+lmbd*np.sum(theta**2)\n",
    "\n",
    "    return theta,cost,r2_score(y,y_pred)\n",
    "\n",
    "best=(None,np.inf,-np.inf)\n",
    "\n",
    "for lr in [0.0001,0.001,0.01,0.1]:\n",
    "    for lmbd in [1e-15,1e-10,1e-5,1e-3,0,1,10,20]:\n",
    "        theta,cost,r2=ridge_gd(X,y,lr,lmbd,1000)\n",
    "        \n",
    "        if np.isfinite(cost) and r2>best[2]:\n",
    "            best=(theta,cost,r2)\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74bb62fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: \n",
      "Linear: 0.29074518557981477 , Ridge: 0.2997888803309673 , Lasso: 0.2990653179473026\n"
     ]
    }
   ],
   "source": [
    "#url='https://drive.google.com/uc?id=1qzCKF6JKKMB0p7ul_lLy8tdmRk3vE_bG'\n",
    "df=pd.read_csv('/Users/anmol117/Downloads/Hitters.csv')\n",
    "\n",
    "df=df.dropna(subset=['Salary'])\n",
    "df=df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "df=pd.get_dummies(df,drop_first=True)\n",
    "\n",
    "X=df.drop('Salary',axis=1)\n",
    "y=df['Salary']\n",
    "\n",
    "sc=StandardScaler()\n",
    "X=sc.fit_transform(X)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "lin=LinearRegression().fit(X_train,y_train)\n",
    "ridge=Ridge(alpha=0.5748).fit(X_train,y_train)\n",
    "lasso=Lasso(alpha=0.5748).fit(X_train,y_train)\n",
    "\n",
    "r2_lin=r2_score(y_test,lin.predict(X_test))\n",
    "r2_ridge=r2_score(y_test,ridge.predict(X_test))\n",
    "r2_lasso=r2_score(y_test,lasso.predict(X_test))\n",
    "\n",
    "print(\"R2 Score: \")\n",
    "print(\"Linear:\", r2_lin,\", Ridge:\", r2_ridge,\", Lasso:\", r2_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "029bfe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rigde: 10.0 , Lasso: 0.1\n"
     ]
    }
   ],
   "source": [
    "df_house=pd.read_csv(\"/Users/anmol117/Downloads/housing.csv\")\n",
    "\n",
    "df_house=df_house.dropna()\n",
    "\n",
    "X=df_house.iloc[:,:-1]\n",
    "y=df_house.iloc[:,-1]\n",
    "\n",
    "sc=StandardScaler()\n",
    "X=sc.fit_transform(X)\n",
    "\n",
    "ridge_cv=RidgeCV(alphas=[0.1,1,10]).fit(X,y)\n",
    "lasso_cv=LassoCV(alphas=[0.1,1,10]).fit(X,y)\n",
    "\n",
    "print(\"Rigde:\",ridge_cv.alpha_,\", Lasso:\", lasso_cv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0adc8036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:  0.9523052464228935\n"
     ]
    }
   ],
   "source": [
    "iris=load_iris()\n",
    "\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "model=LogisticRegression(multi_class='ovr',max_iter=1000).fit(X_train,y_train)\n",
    "\n",
    "r2 = r2_score(y_test,model.predict(X_test))\n",
    "\n",
    "print(\"R2 Score: \", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
